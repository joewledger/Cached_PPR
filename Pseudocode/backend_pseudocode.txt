#Psuedocode for the back-end of the web-application
#Separate from my testing of the properties of cached-PPR


#Things to talk about with David
#What kind of file formats do we want to accept?
#What kind of technology stack are we going to use to cache the stored matrices? A database? Flat-file storage?
#What language do we want to write all this code in? Does the language of my backend code need to match his? Or can we mix/match with convenient interfaces


def RECEIVE_QUERY(filename, query_type, query_parameters):
	#Checks to see if this file and associated data is already cached
	#If it is, get file_id of cached data
	#Otherwise, generate new unique file_id, and map file_id -> filename in database
	file_id <- GET_UNIQUE_FILE_ID(filename)
	if(query_type == BFS):
		results <- EXECUTE_BFS_QUERY(file_id,query_parameters)
	elif(query_type == PPR):
		results <- EXECUTE_PPR_QUERY(file_id,query_parameters)
	DISPLAY_RESULTS(results)

def DISPLAY_RESULTS(results):
	#For David to implement

def EXECUTE_BFS_QUERY(file_id,query_parameters):
	#For David to implement

#Expects the following in query_parameters: "query_nodes","alpha"
def EXECUTE_PPR_QUERY(file_id,query_parameters):

	query_nodes = query_parameters["query_nodes"]
	alpha = query_parameters["alpha"]
	
	#Next four lines are I/O
	UPDATE_MATRIX_CACHE(file_id)
	W <- matrix_cache[file_id]
	UPDATE_PROXIMITY_VECTOR_CACHE(file_id,alpha)
	proximity_vectors = proximity_vector_cache[file_id,alpha,query_nodes]
	
	return CALCULATE_PPR_RESULTS(W,proximity_vectors,query_nodes,alpha)


def UPDATE_MATRIX_CACHE(file_id):

	if(not file_id in matrix_cache):
		W <- GET_SPARSE_MATRIX(file_id)
		W <- GET_LARGEST_CONNECTED_COMPONENT(W)
		W <- COLUMN_NORMALIZE(W)
		matrix_cache[file_id] = W

def UPDATE_PROXIMITY_VECTOR_CACHE(file_id,alpha):

	#TBD based on results of tests:
		#We will either cache new proximity vectors for all new values of alpha,
		#Or we will use alpha values that are sufficiently close to ones we have already cached	
	...

def CALCULATE_PPR_RESULTS(W,proximity_vectors,query_nodes,alpha):
	starting_vector <- COMBINE_PROXIMITY_VECTORS(proximity_vectors)
	restart_vector <- GET_RESTART_VECTOR(W,query_nodes)
	return RUN_PPR(W,starting_vector,restart_vector,alpha)

def GET_SPARSE_MATRIX(file_id) ...
def GET_LARGEST_CONNECTED_COMPONENT(W) ...
def COLUMN_NORMALIZE(W) ...
def COMBINE_PROXIMITY_VECTORS(proximity_vectors) ...
def GET_RESTART_VECTOR(W,query_nodes) ...
def RUN_PPR(W,starting_vector,restart_vector, alpha) ...

	